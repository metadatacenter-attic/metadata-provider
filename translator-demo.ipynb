{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful files and settings (remove in final version):\n",
    "- Dropbox Folder: ‚Å®Dropbox/01.INVESTIGACION/[2020]/2020-03 NCATS Translator Demo\n",
    "- Tool: PyCharm\n",
    "- GitHub repo: cedar-translator-demo\n",
    "- Workspace: workspace folder in the current execution folder\n",
    "- ARM Jupyter notebook: https://nbviewer.jupyter.org/github/metadatacenter/cedar-experiments-valuerecommender2019/blob/master/ValueRecommenderEvaluation.ipynb \n",
    "- cedar-valuerecommender-server: branch 'experiments-curation'\n",
    "\n",
    "\n",
    "# _NCATS Biomedical Data Translator - First Segment (demo)_\n",
    "\n",
    "[Stanford Center for Biomedical Informatics Research](https://bmir.stanford.edu/), 1265 Welch Road, Stanford University School of Medicine, Stanford, CA 94305-5479, USA\n",
    "\n",
    "\\* Correspondence: marcosmr@stanford.edu\n",
    "\n",
    "## Purpose of this document\n",
    "\n",
    "This document is a [Jupyter notebook](http://jupyter.org/) that describes the work done during the first segment of the award to develop prototype metadata-curation functionality and to apply it to a subset of metadata records in the NCBI BioSample repository.\n",
    "\n",
    "The scripts used to generate the results and figures in the paper are in the [scripts folder](./scripts). The results generated when running the code cells in this notebook will be saved to a local `workspace` folder.\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s0\"></a>Viewing and running this notebook\n",
    "\n",
    "GitHub will automatically generate a static online view of this notebook. However, current GitHub's rendering does not support some features, such as the anchor links that connect the 'Table of contents' to the different sections. A more reliable way to view the notebook file online is by using [nbviewer](https://nbviewer.jupyter.org/), which is the official viewer of the Jupyter Notebook project. [Click here](https://nbviewer.jupyter.org/github/metadatacenter/cedar-experiments-curation/blob/master/AAA.ipynb) to open our notebook using nbviewer.\n",
    "\n",
    "The interactive features of our notebook will not work neither from GitHub nor nbviewer. For a fully interactive version of this notebook, you can set up a Jupyter Notebook server locally and start it from the local folder where you cloned the repository. For more information, see [Jupyter's official documentation](https://jupyter.org/install.html). Once your local Jupyter Notebook server is running, go to [http://localhost:8888/](http://localhost:8888/) and click on `translator-demo.ipynb` to open our notebook. You can also run the notebook on [Binder](https://mybinder.org/) by clicking [here](https://mybinder.org/v2/gh/metadatacenter/translator-demo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s1\"></a>Step 1: Dataset download\n",
    "On Jan 14, 2020, we downloaded the full content of the [NCBI BioSample database](https://www.ncbi.nlm.nih.gov/biosample/) from the [NCBI BioSample FTP repository](https://ftp.ncbi.nih.gov/biosample/) as a .gz file. The size of the file downloaded is 944 MB and it contains 12,558,194 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source URL: https://ftp.ncbi.nih.gov/biosample/biosample_set.xml.gz\n",
      "Destination file: ./workspace/samples/source/biosample_set.xml.gz\n",
      "CPU times: user 18.2 s, sys: 7.97 s, total: 26.2 s\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filter the NCBI samples\n",
    "%run ./scripts/step1_download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s2\"></a>Step 2: Filter - Homo sapiens\n",
    "\n",
    "We filtered the initial set of samples to keep only the \"Homo sapiens\" samples (organism=Homo sapiens). We processed a total of 12,558,194 samples and kept a total of 6,279,693 Homo sapiens samples (50%).\n",
    "\n",
    "Script used: [step2_filter_homo_sapiens.py](scripts/step2_filter_homo_sapiens.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The destination file already exist. Do you want to overwrite it [y/n]?Y\n",
      "Input file: ./../workspace/samples/source/biosample_set.xml.gz\n",
      "Output file: ./../workspace/samples/filtered/homo_sapiens/biosample_filtered.xml\n",
      "Processing NCBI samples...\n",
      "Processed samples: 100000\n",
      "Selected samples: 37112\n",
      "Processed samples: 200000\n",
      "Selected samples: 82285\n",
      "Processed samples: 300000\n",
      "Selected samples: 141486\n",
      "Processed samples: 400000\n",
      "Selected samples: 241486\n",
      "Processed samples: 500000\n",
      "Selected samples: 341486\n",
      "Processed samples: 600000\n",
      "Selected samples: 436907\n",
      "Processed samples: 700000\n",
      "Selected samples: 518736\n",
      "Processed samples: 800000\n",
      "Selected samples: 594660\n",
      "Processed samples: 900000\n",
      "Selected samples: 694660\n",
      "Processed samples: 1000000\n",
      "Selected samples: 778747\n",
      "Processed samples: 1100000\n",
      "Selected samples: 854501\n",
      "Processed samples: 1200000\n",
      "Selected samples: 953406\n",
      "Processed samples: 1300000\n",
      "Selected samples: 1053405\n",
      "Processed samples: 1400000\n",
      "Selected samples: 1153405\n",
      "Processed samples: 1500000\n",
      "Selected samples: 1253405\n",
      "Processed samples: 1600000\n",
      "Selected samples: 1353405\n",
      "Processed samples: 1700000\n",
      "Selected samples: 1439435\n",
      "Processed samples: 1800000\n",
      "Selected samples: 1506156\n",
      "Processed samples: 1900000\n",
      "Selected samples: 1588938\n",
      "Processed samples: 2000000\n",
      "Selected samples: 1637070\n",
      "Processed samples: 2100000\n",
      "Selected samples: 1708342\n",
      "Processed samples: 2200000\n",
      "Selected samples: 1753211\n",
      "Processed samples: 2300000\n",
      "Selected samples: 1825995\n",
      "Processed samples: 2400000\n",
      "Selected samples: 1902651\n",
      "Processed samples: 2500000\n",
      "Selected samples: 1958947\n",
      "Processed samples: 2600000\n",
      "Selected samples: 2008841\n",
      "Processed samples: 2700000\n",
      "Selected samples: 2065228\n",
      "Processed samples: 2800000\n",
      "Selected samples: 2113443\n",
      "Processed samples: 2900000\n",
      "Selected samples: 2172121\n",
      "Processed samples: 3000000\n",
      "Selected samples: 2206721\n",
      "Processed samples: 3100000\n",
      "Selected samples: 2244443\n",
      "Processed samples: 3200000\n",
      "Selected samples: 2286303\n",
      "Processed samples: 3300000\n",
      "Selected samples: 2337997\n",
      "Processed samples: 3400000\n",
      "Selected samples: 2423555\n",
      "Processed samples: 3500000\n",
      "Selected samples: 2506062\n",
      "Processed samples: 3600000\n",
      "Selected samples: 2548369\n",
      "Processed samples: 3700000\n",
      "Selected samples: 2620974\n",
      "Processed samples: 3800000\n",
      "Selected samples: 2669254\n",
      "Processed samples: 3900000\n",
      "Selected samples: 2724684\n",
      "Processed samples: 4000000\n",
      "Selected samples: 2764107\n",
      "Processed samples: 4100000\n",
      "Selected samples: 2805309\n",
      "Processed samples: 4200000\n",
      "Selected samples: 2843004\n",
      "Processed samples: 4300000\n",
      "Selected samples: 2875512\n",
      "Processed samples: 4400000\n",
      "Selected samples: 2912384\n",
      "Processed samples: 4500000\n",
      "Selected samples: 2952535\n",
      "Processed samples: 4600000\n",
      "Selected samples: 3006057\n",
      "Processed samples: 4700000\n",
      "Selected samples: 3058560\n",
      "Processed samples: 4800000\n",
      "Selected samples: 3111515\n",
      "Processed samples: 4900000\n",
      "Selected samples: 3191093\n",
      "Processed samples: 5000000\n",
      "Selected samples: 3220860\n",
      "Processed samples: 5100000\n",
      "Selected samples: 3268127\n",
      "Processed samples: 5200000\n",
      "Selected samples: 3300626\n",
      "Processed samples: 5300000\n",
      "Selected samples: 3370748\n",
      "Processed samples: 5400000\n",
      "Selected samples: 3402729\n",
      "Processed samples: 5500000\n",
      "Selected samples: 3440586\n",
      "Processed samples: 5600000\n",
      "Selected samples: 3481213\n",
      "Processed samples: 5700000\n",
      "Selected samples: 3518478\n",
      "Processed samples: 5800000\n",
      "Selected samples: 3567772\n",
      "Processed samples: 5900000\n",
      "Selected samples: 3600612\n",
      "Processed samples: 6000000\n",
      "Selected samples: 3624320\n",
      "Processed samples: 6100000\n",
      "Selected samples: 3675528\n",
      "Processed samples: 6200000\n",
      "Selected samples: 3733474\n",
      "Processed samples: 6300000\n",
      "Selected samples: 3810273\n",
      "Processed samples: 6400000\n",
      "Selected samples: 3844991\n",
      "Processed samples: 6500000\n",
      "Selected samples: 3926719\n",
      "Processed samples: 6600000\n",
      "Selected samples: 3976945\n",
      "Processed samples: 6700000\n",
      "Selected samples: 4024798\n",
      "Processed samples: 6800000\n",
      "Selected samples: 4067550\n",
      "Processed samples: 6900000\n",
      "Selected samples: 4088028\n",
      "Processed samples: 7000000\n",
      "Selected samples: 4120584\n",
      "Processed samples: 7100000\n",
      "Selected samples: 4169576\n",
      "Processed samples: 7200000\n",
      "Selected samples: 4213575\n",
      "Processed samples: 7300000\n",
      "Selected samples: 4246989\n",
      "Processed samples: 7400000\n",
      "Selected samples: 4285607\n",
      "Processed samples: 7500000\n",
      "Selected samples: 4332923\n",
      "Processed samples: 7600000\n",
      "Selected samples: 4422233\n",
      "Processed samples: 7700000\n",
      "Selected samples: 4463457\n",
      "Processed samples: 7800000\n",
      "Selected samples: 4514128\n",
      "Processed samples: 7900000\n",
      "Selected samples: 4558768\n",
      "Processed samples: 8000000\n",
      "Selected samples: 4601320\n",
      "Processed samples: 8100000\n",
      "Selected samples: 4636091\n",
      "Processed samples: 8200000\n",
      "Selected samples: 4672292\n",
      "Processed samples: 8300000\n",
      "Selected samples: 4720584\n",
      "Processed samples: 8400000\n",
      "Selected samples: 4758278\n",
      "Processed samples: 8500000\n",
      "Selected samples: 4808679\n",
      "Processed samples: 8600000\n",
      "Selected samples: 4847299\n",
      "Processed samples: 8700000\n",
      "Selected samples: 4905892\n",
      "Processed samples: 8800000\n",
      "Selected samples: 4961702\n",
      "Processed samples: 8900000\n",
      "Selected samples: 5000115\n",
      "Processed samples: 9000000\n",
      "Selected samples: 5041339\n",
      "Processed samples: 9100000\n",
      "Selected samples: 5069726\n",
      "Processed samples: 9200000\n",
      "Selected samples: 5097216\n",
      "Processed samples: 9300000\n",
      "Selected samples: 5131187\n",
      "Processed samples: 9400000\n",
      "Selected samples: 5182461\n",
      "Processed samples: 9500000\n",
      "Selected samples: 5234255\n",
      "Processed samples: 9600000\n",
      "Selected samples: 5257784\n",
      "Processed samples: 9700000\n",
      "Selected samples: 5288207\n",
      "Processed samples: 9800000\n",
      "Selected samples: 5327547\n",
      "Processed samples: 9900000\n",
      "Selected samples: 5357936\n",
      "Processed samples: 10000000\n",
      "Selected samples: 5380633\n",
      "Processed samples: 10100000\n",
      "Selected samples: 5424237\n",
      "Processed samples: 10200000\n",
      "Selected samples: 5454381\n",
      "Processed samples: 10300000\n",
      "Selected samples: 5478741\n",
      "Processed samples: 10400000\n",
      "Selected samples: 5505855\n",
      "Processed samples: 10500000\n",
      "Selected samples: 5528826\n",
      "Processed samples: 10600000\n",
      "Selected samples: 5573005\n",
      "Processed samples: 10700000\n",
      "Selected samples: 5617409\n",
      "Processed samples: 10800000\n",
      "Selected samples: 5646522\n",
      "Processed samples: 10900000\n",
      "Selected samples: 5670865\n",
      "Processed samples: 11000000\n",
      "Selected samples: 5716079\n",
      "Processed samples: 11100000\n",
      "Selected samples: 5801051\n",
      "Processed samples: 11200000\n",
      "Selected samples: 5831905\n",
      "Processed samples: 11300000\n",
      "Selected samples: 5850059\n",
      "Processed samples: 11400000\n",
      "Selected samples: 5884881\n",
      "Processed samples: 11500000\n",
      "Selected samples: 5913710\n",
      "Processed samples: 11600000\n",
      "Selected samples: 5965738\n",
      "Processed samples: 11700000\n",
      "Selected samples: 5977946\n",
      "Processed samples: 11800000\n",
      "Selected samples: 5994405\n",
      "Processed samples: 11900000\n",
      "Selected samples: 6019202\n",
      "Processed samples: 12000000\n",
      "Selected samples: 6029851\n",
      "Processed samples: 12100000\n",
      "Selected samples: 6060487\n",
      "Processed samples: 12200000\n",
      "Selected samples: 6096256\n",
      "Processed samples: 12300000\n",
      "Selected samples: 6143781\n",
      "Processed samples: 12400000\n",
      "Selected samples: 6200411\n",
      "Processed samples: 12500000\n",
      "Selected samples: 6243067\n",
      "Finished processing NCBI samples\n",
      "- Total samples processed: 12558194\n",
      "- Total samples selected: 6279693\n",
      "CPU times: user 5h 15min 37s, sys: 1min 18s, total: 5h 16min 56s\n",
      "Wall time: 5h 17min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filter the NCBI samples\n",
    "%run ./scripts/step2_filter_homo_sapiens.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s3\"></a>Step 2: Preliminary analysis - Attribute names from Homo sapiens samples\n",
    "\n",
    "Script used: [step3_analysis_attributes.py](scripts/step3_analysis_attributes.py).\n",
    "\n",
    "This analysis is limited to the 6.3M BioSample Homo sapiens samples coming from the previous step. \n",
    "\n",
    "The execution of this script will generate four .csv files with the values of the three attributes used in the BioSample XML file to store the attribute names:\n",
    "* attribute_names.csv: Attribute names and count.\n",
    "* display_names.csv: Display names and count.\n",
    "* harmonized_names.csv: Harmonized names and count.\n",
    "* all_names.csv: Combination of attribute name, display name, and harmonized name, and its count.\n",
    "\n",
    "These files will be stored at the [workspace/samples/analysis](workspace/samples/analysis) folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file: ./workspace/samples/filtered/homo_sapiens/biosample_filtered.xml\n",
      "Processing NCBI samples...\n",
      "Processed samples: 100000\n",
      "Processed samples: 200000\n",
      "Processed samples: 300000\n",
      "Processed samples: 400000\n",
      "Processed samples: 500000\n",
      "Processed samples: 600000\n",
      "Processed samples: 700000\n",
      "Processed samples: 800000\n",
      "Processed samples: 900000\n",
      "Processed samples: 1000000\n",
      "Processed samples: 1100000\n",
      "Processed samples: 1200000\n",
      "Processed samples: 1300000\n",
      "Processed samples: 1400000\n",
      "Processed samples: 1500000\n",
      "Processed samples: 1600000\n",
      "Processed samples: 1700000\n",
      "Processed samples: 1800000\n",
      "Processed samples: 1900000\n",
      "Processed samples: 2000000\n",
      "Processed samples: 2100000\n",
      "Processed samples: 2200000\n",
      "Processed samples: 2300000\n",
      "Processed samples: 2400000\n",
      "Processed samples: 2500000\n",
      "Processed samples: 2600000\n",
      "Processed samples: 2700000\n",
      "Processed samples: 2800000\n",
      "Processed samples: 2900000\n",
      "Processed samples: 3000000\n",
      "Processed samples: 3100000\n",
      "Processed samples: 3200000\n",
      "Processed samples: 3300000\n",
      "Processed samples: 3400000\n",
      "Processed samples: 3500000\n",
      "Processed samples: 3600000\n",
      "Processed samples: 3700000\n",
      "Processed samples: 3800000\n",
      "Processed samples: 3900000\n",
      "Processed samples: 4000000\n",
      "Processed samples: 4100000\n",
      "Processed samples: 4200000\n",
      "Processed samples: 4300000\n",
      "Processed samples: 4400000\n",
      "Processed samples: 4500000\n",
      "Processed samples: 4600000\n",
      "Processed samples: 4700000\n",
      "Processed samples: 4800000\n",
      "Processed samples: 4900000\n",
      "Processed samples: 5000000\n",
      "Processed samples: 5100000\n",
      "Processed samples: 5200000\n",
      "Processed samples: 5300000\n",
      "Processed samples: 5400000\n",
      "Processed samples: 5500000\n",
      "Processed samples: 5600000\n",
      "Processed samples: 5700000\n",
      "Processed samples: 5800000\n",
      "Processed samples: 5900000\n",
      "Processed samples: 6000000\n",
      "Processed samples: 6100000\n",
      "Processed samples: 6200000\n",
      "Finished processing NCBI samples\n",
      "- Total samples processed: 6279693\n",
      "CPU times: user 2h 34min 38s, sys: 25.5 s, total: 2h 35min 3s\n",
      "Wall time: 2h 35min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filter the NCBI samples\n",
    "%run ./scripts/step3_analysis_attributes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the array with the required attributes we only include as variations those strings are don't have a corresponding harmonized name.\n",
    "\n",
    "See official synonyms at: https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/\n",
    "\n",
    "Results of analysis:\n",
    "\n",
    "Attribute name: sex\n",
    "* Variations (harmonized)\n",
    "    * sex (4,625,561)\n",
    "    * Sex (193,644)\n",
    "    * gender (32,323)\n",
    "    * GENDER (7,838)\n",
    "    * ArrayExpress-Sex (3,324)\n",
    "    * DONOR_SEX (926)\n",
    "    * donor sex (480)\n",
    "    * Gender (387)\n",
    "    * SEX (292)\n",
    "    * ArrayExpress-SEX (268)\n",
    "    * sample gender (90)\n",
    "    * Experimental Factor: Sex (8)\n",
    "* Variations (non-harmonized)\n",
    "    * cell sex (2,543)  \n",
    "    * patient gender (1,038)\n",
    "    * donor gender (617)\n",
    "    * patient_gender (417)\n",
    "    * c_sex_all (483)\n",
    "    * subject sex (468)\n",
    "    * subject gender (203)\n",
    "    * Array's reference DNA's sex (170)\n",
    "    * DNA sex (102)\n",
    "    * fetal sex (98) (?)\n",
    "    * biological sex (92)\n",
    "    * fetal gender (76) (?)\n",
    "    * cell line source gender (75)\n",
    "    * patient sex (73)\n",
    "    * biologic sex (92)\n",
    "    * gender source (16) (?)\n",
    "    * sex of donor (12)\n",
    "    * gender of donor (12)\n",
    "    * human gender (12)\n",
    "    * sex chromosomes (6)\n",
    "    * sex/karyotype (5)\n",
    "    * cell source subject gender (3)\n",
    "    * biological_sex (1)\n",
    "\n",
    "Attribute name: tissue\n",
    "* Variations (harmonized)\n",
    "    * body site (2797078)\n",
    "\t* tissue (454459)\n",
    "\t* organism part (216833)\n",
    "\t* tissue_type (12198)\n",
    "\t* organ (7261)\n",
    "\t* Tissue (4005)\n",
    "\t* tissue type (3723)\n",
    "\t* body_site (3285)\n",
    "\t* tissue-type (2240)\n",
    "\t* source tissue (700)\n",
    "\t* TISSUE_TYPE (467)\n",
    "\t* tissue origin (419)\n",
    "\t* OrganismPart (167)\n",
    "\t* TISSUE (161)\n",
    "\t* ArrayExpress-OrganismPart (148)\n",
    "\t* ArrayExpress-ORGANISM_PART (84)\n",
    "\t* tissuetype (79)\n",
    "\t* tissue_origin (60)\n",
    "\t* tisssue (8)\n",
    "\t* Tissue Type (2)\n",
    "* Variations (non-harmonized)\n",
    "\t* tissue supergroup (9361) (I've checked that this is equivalent to tissue. Query: \"tissue supergroup=lung\"[attr]) \n",
    "\t* tissue source (2680)\n",
    "\t* metastatic tissue (1593)\n",
    "    * DiseaseLocation (1008)\n",
    "\t* tissue subtype (766)\n",
    "\t* tissue archive method (382)\n",
    "\t* tissue compartment (370)\n",
    "\t* tissue of origin (311)\n",
    "\t* tissue/cell type source (204)\n",
    "\t* tissue region (169)\n",
    "\t* tissue id (153)\n",
    "\t* tissue diagnosis (139)\n",
    "\t* tissue preparation (122)\n",
    "\t* tissue collection (95)\n",
    "\t* tissue/treatment id (84)\n",
    "\t* tissue/cells (74)\n",
    "\t* tissue/position (73)\n",
    "\t* metatastic tissue (68)\n",
    "\t* tissue side (66)\n",
    "\t* resident tissue (66)\n",
    "\t* tissue/status (60)\n",
    "\t* tissue harvest site (58)\n",
    "\t* type of liver tissue (48)\n",
    "\t* tissue processing (47)\n",
    "\t* tissue state (46)\n",
    "\t* tissue derivation (44)\n",
    "\t* tissue nature (44)\n",
    "\t* Tissue collected (43)\n",
    "\t* tissue source/type (41)\n",
    "\t* tissue subtype/brodmann area (41)\n",
    "\t* cell line or tissue (40)\n",
    "\t* cell or tissue type (40)\n",
    "\t* cell/tissue type (39)\n",
    "\t* tissue lineage (34)\n",
    "\t* developmental stage/tissue (30)\n",
    "\t* primary tissue (26)\n",
    "\t* thyroid tissue type (20)\n",
    "\t* tissue/cell line (20)\n",
    "\t* tissue culture substrate (20)\n",
    "\t* cell_line/tissue (19)\n",
    "\t* tissue storage (18)\n",
    "\t* date of tissue preparation (18)\n",
    "\t* cancer tissue source (18)\n",
    "\t* Reason why donor tissue was not suitable for transplantation (18)\n",
    "\t* tissue site (17)\n",
    "\t* idh1 status in tumor tissue (15)\n",
    "\t* tissue condition (15)\n",
    "\t* cell line/tissue (15)\n",
    "\t* cell-type/tissue (14)\n",
    "\t* tissue disease state (14)\n",
    "\t* tissue group (13)\n",
    "\t* cell line tissue source (13)\n",
    "\t* originating tissue (12)\n",
    "\t* tissue section (12)\n",
    "\t* primary tumor tissue (12)\n",
    "\t* adjacent normal tissue (12)\n",
    "\t* tissue source and immunoselection of cells (12)\n",
    "\t* tissue soure (11)\n",
    "\t* tissue location (10)\n",
    "\t* tissue code (9)\n",
    "\t* xenograft tissue (6)\n",
    "\t* cell line source tissue (6)\n",
    "\t* tissue/cell (5)\n",
    "\t* mouse tissue (5)\n",
    "\t* gestional age of tissue (5)\n",
    "\t* location in tissue (4)\n",
    "\t* tissue cell line (4)\n",
    "\t* orginal tissue (4)\n",
    "\t* developmental tissue (4)\n",
    "\t* tissue type/source (3)\n",
    "\t* tissue appendix (2)\n",
    "\t* tissue resource (2)\n",
    "\t* tissue status (2)\n",
    "\t* primary tissue status (1)\n",
    "\n",
    "Attribute name: disease\n",
    "* Variations (harmonized)\n",
    "    * disease state (197,153)\n",
    "\t* disease (118,836)\n",
    "\t* disease status (5596)\n",
    "\t* DISEASE (1375)\n",
    "\t* Disease (235)\n",
    "\t* diseasestatus (214)\n",
    "\t* DiseaseState (152)\n",
    "\t* ArrayExpress-DiseaseState (148)\n",
    "\t* disease_state (30)\n",
    "\t* disease_status (26)\n",
    "\t* diseases (24)\n",
    "\t* Disease Status (8)\n",
    "\t* ArrayExpress-DISEASE_STATE (2)\n",
    "* Variations (non-harmonized)\n",
    "\t* diseaseseverity (13126) (I've checked that it's equivalent to disease)\n",
    "\t* disease staging (8599)\n",
    "\t* DiseaseStaging (7933)\n",
    "\t* clincial information - disease outcome (1006)\n",
    "\t* original disease abbreviation (935)\n",
    "\t* original disease annotation (932)\n",
    "\t* disease group (655)\n",
    "\t* disease detection (522)\n",
    "\t* death from disease (498)\n",
    "\t* CIS in disease course (476)\n",
    "\t* Disease staging (458)\n",
    "\t* DiseaseOutcome (456)\n",
    "\t* disease recurrence (349)\n",
    "\t* DiseaseStateDatabase (326)\n",
    "\t* tb_disease_type (313)\n",
    "\t* disease progression (binary) (306)\n",
    "\t* time since diagnosis of advanced disease (306)\n",
    "\t* disease type (288)\n",
    "\t* DiseaseFreeInterval (268)\n",
    "\t* disease subtype (268)\n",
    "\t* DiseaseLocati (264)\n",
    "\t* dead of disease (258)\n",
    "\t* DiseaseFactor (232)\n",
    "\t* ClinicalInformation:Disease subtype (202)\n",
    "\t* disease status at last clinical followup (155)\n",
    "\t* DEATH RELATED TO DISEASE (146)\n",
    "\t* disease free survival (142)\n",
    "\t* histology of invasive disease (129)\n",
    "\t* disease classification (126)\n",
    "\t* tfc_disease_stage (124)\n",
    "\t* disease_phenotype_replicate (124)\n",
    "\t* status of disease (121)\n",
    "\t* disease activity (120)\n",
    "\t* LengthOfDisease (113)\n",
    "\t* PriorTherapiesForPrimaryDiseaseUnderStudy (113)\n",
    "\t* DiseaseStateOfSample (101)\n",
    "\t* Disease-Free Survival Status (100)\n",
    "\t* Day 7 Minimal Residual Disease (98)\n",
    "\t* primary disease (96)\n",
    "\t* Disease factor (94)\n",
    "\t* Day 28 Minimal Residual Disease (86)\n",
    "\t* disease abbreviation (78)\n",
    "\t* originalDisease (77)\n",
    "\t* disease_severity (66)\n",
    "\t* Day 14 Minimal Residual Disease (56)\n",
    "\t* DiseaseRecurrence (50)\n",
    "\t* disease_age_at_onset (47)\n",
    "\t* DiseaseFreeAfterTwoYears (44)\n",
    "\t* disease diagnosis (44)\n",
    "\t* characteristics:disease (43)\n",
    "\t* disease_subtype (43)\n",
    "\t* disease condition (39)\n",
    "\t* disease level (38)\n",
    "\t* disease at diagnosis (36)\n",
    "\t* disease_duration_days (35)\n",
    "\t* DiseaseSta (32)\n",
    "\t* disease_duration_yrs (30)\n",
    "\t* underlying disease (29)\n",
    "\t* disease/status (28)\n",
    "\t* donor disease status (28)\n",
    "\t* family history of diverticular disease (26)\n",
    "\t* disease onset (24)\n",
    "\t* disease course (24)\n",
    "\t* cause of liver disease (24)\n",
    "\t* primary_disease (23)\n",
    "\t* DISEASE_ONTOLOGY_URI (22)\n",
    "\t* disease severity (22)\n",
    "\t* disease/health status (21)\n",
    "\t* disease site (21)\n",
    "\t* disease_diagnose (20)\n",
    "\t* disease duration in weeks (19)\n",
    "\t* Disease_Factor (18)\n",
    "\t* pre-transplant disease (17)\n",
    "\t* DiseaseType (16)\n",
    "\t* coronary artery disease status (16)\n",
    "\t* cardiac disease (16)\n",
    "\t* tissue disease state (14)\n",
    "\t* disease_extent (13)\n",
    "\t* disease/genotype (12)\n",
    "\t* disease model (12)\n",
    "\t* DiseaseStateOfSample1 (12)\n",
    "\t* disease_type (9)\n",
    "\t* current disease Stage (8)\n",
    "\t* disease ontology uri (6)\n",
    "\t* age/disease (6)\n",
    "\t* disease_duration_years (6)\n",
    "\t* disease_length (5)\n",
    "\t* diseaset state (4)\n",
    "\t* siod disease status (2)\n",
    "\t* disease associated genotype (1)\n",
    "\t* disease_state_sample (1)\n",
    "\t* disease.ontology (1)\n",
    "\t* disease.text (1)\n",
    "\n",
    "\n",
    "In order to perform the filtering, we will use the harmonized name for each attribute plus the non-harmonized variations that have more than 500 occurrences. That is, we will use the following variations:\n",
    "\n",
    "```json\n",
    "NCBI_FILTER_RELEVANT_ATTS_1 = \\\n",
    "    [{\"name\": \"sex\", \"variations\": [\"sex\", \"cell sex\", \"patient gender\", \"donor gender\"]},\n",
    "    {\"name\": \"tissue\", \"variations\": [\"tissue\", \"tissue supergroup\", \"tissue source\", \"metastatic tissue\", \n",
    "                                      \"DiseaseLocation\", \"tissue subtype\"]},\n",
    "    {\"name\": \"disease\", \"variations\": [\"disease\", \"diseaseseverity\", \"disease staging\", \"DiseaseStaging\",\n",
    "                                       \"clincial information - disease outcome\", \n",
    "                                       \"original disease abbreviation\",\n",
    "                                       \"original disease annotation\", \"disease group\"]}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------ STOPPED HERE -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s2\"></a>Step 2: Filter: Homo sapiens\n",
    "\n",
    "We filtered the initial set of samples based on two criteria:\n",
    "* The sample is from \"Homo sapiens\" (organism=Homo sapiens).\n",
    "* The sample has non-empty values for all the following fields: *age, sex, tissue, cell line, cell type, disease*\n",
    "\n",
    "Script used: [step2_preliminary_filtering.py](scripts/step2_preliminary_filtering.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Filter the NCBI samples\n",
    "%run ./scripts/step2_preliminary_filtering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"s2-2\"></a>2.2. Select samples\n",
    "\n",
    "We filtered the samples based on two criteria:\n",
    "* The sample is from \"Homo sapiens\" (organism=Homo sapiens).\n",
    "* The sample has non-empty values for at least 3 of the 6 fields listed in the previous section.\n",
    "\n",
    "#### <a name=\"s2-2-a\"></a>2.2.a. NCBI BioSample\n",
    "\n",
    "Script used: [step2_filtering.py](scripts/step2_filtering.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Filter the NCBI samples\n",
    "%run ./scripts/step2_filtering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution results:\n",
    "Finished processing NCBI samples\n",
    "- Total samples processed: 11,625,524\n",
    "- Total samples selected: 262,114\n",
    "\n",
    "The result is an XML file with 262,114 samples ([biosample_filtered.xml](./workspace/samples/filtered/biosample_filtered.xml)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"s2-3\"></a>2.3. Generate CEDAR instances\n",
    "\n",
    "We transformed the samples obtained from the previous step to CEDAR template instances conforming to [CEDAR's JSON-based Template Model](https://metadatacenter.org/tools-training/outreach/cedar-template-model).\n",
    "\n",
    "Script used: [step3_instance_generation.py](scripts/step3_instance_generation.py): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ./workspace/samples/filtered/biosample_filtered.xml\n",
      "Extracting all samples from file (no. samples: 262114)\n",
      "Randomly picking 262114 samples\n",
      "Generating CEDAR instances...\n",
      "No. instances generated: 10000 (4%)\n",
      "No. instances generated: 20000 (8%)\n",
      "No. instances generated: 30000 (11%)\n",
      "No. instances generated: 40000 (15%)\n",
      "No. instances generated: 50000 (19%)\n",
      "No. instances generated: 60000 (23%)\n",
      "No. instances generated: 70000 (27%)\n",
      "No. instances generated: 80000 (31%)\n",
      "No. instances generated: 90000 (34%)\n",
      "No. instances generated: 100000 (38%)\n",
      "No. instances generated: 110000 (42%)\n",
      "No. instances generated: 120000 (46%)\n",
      "No. instances generated: 130000 (50%)\n",
      "No. instances generated: 140000 (53%)\n",
      "No. instances generated: 150000 (57%)\n",
      "No. instances generated: 160000 (61%)\n",
      "No. instances generated: 170000 (65%)\n",
      "No. instances generated: 180000 (69%)\n",
      "No. instances generated: 190000 (72%)\n",
      "No. instances generated: 200000 (76%)\n",
      "No. instances generated: 210000 (80%)\n",
      "No. instances generated: 220000 (84%)\n",
      "No. instances generated: 230000 (88%)\n",
      "No. instances generated: 240000 (92%)\n",
      "No. instances generated: 250000 (95%)\n",
      "No. instances generated: 260000 (99%)\n",
      "Finished\n",
      "CPU times: user 2min 40s, sys: 40.5 s, total: 3min 20s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate CEDAR instances from NCBI samples\n",
    "%run ./scripts/step3_instance_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s4\"></a>Step 3: Generation of experimental data sets\n",
    "\n",
    "When we generated the CEDAR instances (step 2.3), we partitioned the resulting instances for each database (NCBI, EBI) into two datasets, with 85% of the data for training and the remaining 15% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"s5\"></a>Step 5: Training\n",
    "\n",
    "We mined association rules from the training sets to discover the hidden relationships between metadata fields. We extracted the rules using a local installation of the CEDAR Workbench. We set up the Value Recommender service to read the instance files from a local folder by updating the [Constants.java](https://github.com/metadatacenter/cedar-valuerecommender-server/blob/master/cedar-valuerecommender-server-core/src/main/java/org/metadatacenter/intelligentauthoring/valuerecommender/util/Constants.java) file as follows:\n",
    "\n",
    "```Java\n",
    "READ_INSTANCES_FROM_CEDAR = false // Read training instances from a local folder\n",
    "```\n",
    "\n",
    "Uupdate the variable `CEDAR_INSTANCES_PATH` with the full path of the corresponding training set: `workspace/cedar_instances/ncbi_cedar_instances/training`\n",
    "\n",
    "Internally, CEDAR's Value Recommender uses a [WEKA's implementation of the Apriori algorithm](https://www.cs.waikato.ac.nz/ml/weka/).\n",
    "\n",
    "Compile the `cedar-valuerecommender-server` project and start it locally. You can trigger the rule generation process from the command line using the following curl command:\n",
    "```\n",
    "curl --request POST \\\n",
    "  --url https://valuerecommender.metadatacenter.orgx/command/generate-rules/<TEMPLATE_ID> \\\n",
    "  --header 'authorization: apiKey <CEDAR_ADMIN_API_KEY>' \\\n",
    "  --header 'content-type: application/json' \\\n",
    "  --data '{}'\n",
    "```\n",
    "\n",
    "where `CEDAR_ADMIN_API_KEY` is the API key of the *cedar-admin* user in your local CEDAR system, and `TEMPLATE_ID` is the local identifier of the template that you want to extract rules for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------end of document-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Rules generation\n",
    "Take the text instances from the arm experiment and run the server with the READ_INSTANCES_FROM_CEDAR constant set to false, and with the right path for the constant CEDAR_INSTANCES_PATH.\n",
    "\n",
    "### Rules ingestion\n",
    "\n",
    "1. Delete the existing rules in Elasticsearch: `cedarat rules-regenerateIndex`\n",
    "2. Download the NCBI (text-based) rules: https://drive.google.com/file/d/1ngCTGf4To1NZ1puRsB3aaCvtZIAERktY/view?usp=sharing\n",
    "3. Extract the rules to a local folder. Then, import the 30,295 rules using:\n",
    "    \n",
    "    `elasticdump --input=./ncbi-text-rules-data.json --output=http://localhost:9200/cedar-rules --type=data`\n",
    "    \n",
    "    \n",
    "4. Check that the rules have been imported correctly using Kibana (http://localhost:5601):\n",
    "    \n",
    "    `GET cedar-rules/_search`\n",
    "    \n",
    "5. Script used to generate recommendations: ...    \n",
    "\n",
    "Notes:\n",
    "- I will use the rules generated from the training set. Then, I will use the test set to evaluate the curation process.\n",
    "\n",
    "Other possible topics to mention:\n",
    "- Configuration settings\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "* ARM-evaluation Jupyter notebook: https://nbviewer.jupyter.org/github/metadatacenter/cedar-experiments-valuerecommender2019/blob/master/ValueRecommenderEvaluation.ipynb#s5-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticdump --input=./ncbi-text-data.json --output=http://localhost:9200/cedar-rules --type=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticdump --input=./ncbi-text-data.json --output=http://localhost:9200/cedar-rules --type=data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
